{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "from langchain.tools.retriever import create_retriever_tool #Tool for retrieving data\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import os\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain import hub #To get the prompt to use\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool #using tool to accomodate any model\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents import create_tool_calling_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Toolf for wikipedia'''\n",
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "wiki.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/ecommercesearchai/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 5 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 73843.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'FastEmbedEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7f03d416a4a0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Retriever for obtaining data from the given website'''\n",
    "\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "vectordb=FAISS.from_documents(documents,FastEmbedEmbeddings())\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name of model :langsmith_search\\nDescription(will be passed to LLM : Search for information about LangSmith. For any questions about LangSmith, you must use this tool! ) '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Tool for retrieving data from the given website'''\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")\n",
    "\n",
    "'''name of model :langsmith_search\n",
    "Description(will be passed to LLM : Search for information about LangSmith. For any questions about LangSmith, you must use this tool! ) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Arxiv Tool'''\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Combining all the tools'''\n",
    "tools=[wiki,arxiv,retriever_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['ANTHROPIC_API_KEY'] = ''\n",
    "model = ChatAnthropic(model='claude-3-opus-20240229')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/mambaforge/envs/ecommercesearchai/lib/python3.10/site-packages/langchain/hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Binding the tools over the specified model'''\n",
    "llm_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Agent and Agent executor'''\n",
    "\n",
    "agent = create_tool_calling_agent(llm_with_tools, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Langsmith'}`\n",
      "responded: [{'text': '<thinking>\\nTo answer the question \"Tell me about Langsmith\", the most relevant tool is langsmith_search, which searches for information specifically about Langsmith. The query parameter can be inferred as simply \"Langsmith\" based on the user\\'s request.\\n\\nThe wikipedia and arxiv tools are not relevant here, as they search for general knowledge and scientific papers respectively, while the question is asking for information about the Langsmith company itself.\\n\\nSince the required query parameter for langsmith_search can be inferred from the user\\'s request, I can proceed with making that tool call without needing to ask for any clarification or additional information from the user first.\\n</thinking>', 'type': 'text', 'index': 0}, {'id': 'toolu_012G9k52iTzJMLL6Fz9ZTLNn', 'input': {}, 'name': 'langsmith_search', 'type': 'tool_use', 'index': 1, 'partial_json': '{\"query\": \"Langsmith\"}'}]\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mGet started with LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith\n",
      "\n",
      "Skip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick startTutorialsHow-to guidesConceptsReferencePricingSelf-hostingLangGraph CloudQuick startOn this pageGet started with LangSmithLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain is not necessary - LangSmith works on its own!1. Install LangSmith‚ÄãPythonTypeScriptpip install -U langsmithyarn add langsmith2. Create an API key‚ÄãTo create an API key head to the Settings page. Then click Create API Key.3. Set up your environment‚ÄãShellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>4. Log your first trace‚ÄãTracing to LangSmith for LangChain usersThere is no need to use the LangSmith SDK directly if your application is built entirely on LangChain\n",
      "\n",
      "Log your first trace‚ÄãTracing to LangSmith for LangChain usersThere is no need to use the LangSmith SDK directly if your application is built entirely on LangChain (either Python and JS).We've outlined a tracing guide specifically for LangChain users here.We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "\n",
      "description=\"A sample dataset in LangSmith.\")client.create_examples(    inputs=[        {\"postfix\": \"to LangSmith\"},        {\"postfix\": \"to Evaluations in LangSmith\"},    ],    outputs=[        {\"output\": \"Welcome to LangSmith\"},        {\"output\": \"Welcome to Evaluations in LangSmith\"},    ],    dataset_id=dataset.id,)# Define your evaluatordef exact_match(run, example):    return {\"score\": run.outputs[\"output\"] == example.outputs[\"output\"]}experiment_results = evaluate(    lambda input: \"Welcome \" + input['postfix'], # Your AI system goes here    data=dataset_name, # The data to predict and grade over    evaluators=[exact_match], # The evaluators to score the results    experiment_prefix=\"sample-experiment\", # The name of the experiment    metadata={      \"version\": \"1.0.0\",      \"revision_id\": \"beta\"    },)import { Client, Run, Example } from \"langsmith\";import { evaluate } from \"langsmith/evaluation\";import { EvaluationResult } from \"langsmith/evaluation\";const client = new\u001b[0m\u001b[32;1m\u001b[1;3m[{'text': '\\n\\n<search_quality_reflection>\\nThe langsmith_search results provide a good overview of what Langsmith is and how to get started using it. It explains that Langsmith is a platform for building LLM applications that allows for close monitoring and evaluation. It gives step-by-step instructions for installing Langsmith, creating an API key, setting up your environment, and logging your first trace. \\n\\nThe results focus mainly on the technical details of getting started, such as the specific commands to run. To fully answer the question of \"Tell me about Langsmith\", some additional high-level information on Langsmith\\'s key features and benefits compared to alternatives would be helpful to include. But overall, the search results are quite relevant and informative for someone looking to learn about Langsmith at an introductory level.\\n</search_quality_reflection>\\n<search_quality_score>4</search_quality_score>\\n\\n<result>\\nLangsmith is a platform that allows you to build production-grade applications powered by large language models (LLMs). Some key features of Langsmith:\\n\\n- Provides tools to closely monitor and evaluate your LLM application, helping you ship quickly and with confidence\\n- Works standalone or can integrate with the LangChain framework \\n- Enables logging traces of your application\\'s activity\\n- Supports experimentation and evaluation of your AI models\\n\\nTo get started with Langsmith, you first install the Langsmith package using pip for Python or yarn for JavaScript. Next, you create an API key in the Langsmith settings. Then you set up your environment variables, including the LANGCHAIN_API_KEY which should be set to your Langsmith API key. \\n\\nOnce set up, you can start logging traces of your application\\'s behavior to Langsmith. This is done automatically if using LangChain. You can also manually instrument tracing using the Langsmith SDK.\\n\\nLangsmith also provides tools for evaluating your models over datasets. You define custom evaluator functions to score the model\\'s outputs, run experiments, and analyze the results to understand your model\\'s performance.\\n\\nSo in summary, Langsmith aims to be an end-to-end platform to build, monitor, evaluate and deploy LLM-based applications to production. It provides observability and experimentation tools to help ensure your AI system meets the required quality bar.\\n</result>', 'type': 'text', 'index': 0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': [{'text': '\\n\\n<search_quality_reflection>\\nThe langsmith_search results provide a good overview of what Langsmith is and how to get started using it. It explains that Langsmith is a platform for building LLM applications that allows for close monitoring and evaluation. It gives step-by-step instructions for installing Langsmith, creating an API key, setting up your environment, and logging your first trace. \\n\\nThe results focus mainly on the technical details of getting started, such as the specific commands to run. To fully answer the question of \"Tell me about Langsmith\", some additional high-level information on Langsmith\\'s key features and benefits compared to alternatives would be helpful to include. But overall, the search results are quite relevant and informative for someone looking to learn about Langsmith at an introductory level.\\n</search_quality_reflection>\\n<search_quality_score>4</search_quality_score>\\n\\n<result>\\nLangsmith is a platform that allows you to build production-grade applications powered by large language models (LLMs). Some key features of Langsmith:\\n\\n- Provides tools to closely monitor and evaluate your LLM application, helping you ship quickly and with confidence\\n- Works standalone or can integrate with the LangChain framework \\n- Enables logging traces of your application\\'s activity\\n- Supports experimentation and evaluation of your AI models\\n\\nTo get started with Langsmith, you first install the Langsmith package using pip for Python or yarn for JavaScript. Next, you create an API key in the Langsmith settings. Then you set up your environment variables, including the LANGCHAIN_API_KEY which should be set to your Langsmith API key. \\n\\nOnce set up, you can start logging traces of your application\\'s behavior to Langsmith. This is done automatically if using LangChain. You can also manually instrument tracing using the Langsmith SDK.\\n\\nLangsmith also provides tools for evaluating your models over datasets. You define custom evaluator functions to score the model\\'s outputs, run experiments, and analyze the results to understand your model\\'s performance.\\n\\nSo in summary, Langsmith aims to be an end-to-end platform to build, monitor, evaluate and deploy LLM-based applications to production. It provides observability and experimentation tools to help ensure your AI system meets the required quality bar.\\n</result>',\n",
       "   'type': 'text',\n",
       "   'index': 0}]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m[{'text': '<thinking>\\nThe arxiv tool seems most relevant to answer this query since it allows searching for the latest scientific articles on arxiv.org in a variety of fields. To use the arxiv tool, I need to provide a search query.\\n\\nThe user has requested information about a \"latest paper in Arxiv\", but hasn\\'t specified a particular subject area. To get the most relevant latest paper, it would help to narrow down the search to a specific field or topic.\\n\\nSince the user didn\\'t provide a particular area to focus on, I will ask them to clarify what subject they are most interested in hearing about the latest research on. This additional context will allow me to construct a more targeted search query for the arxiv tool.\\n</thinking>\\n\\nTo find the most relevant latest paper on Arxiv for you, it would help to know what subject area or topic you are most interested in. Arxiv covers a wide range of fields including Physics, Mathematics, Computer Science, Biology, Finance, Statistics, Engineering, and Economics.\\n\\nCould you specify a particular subject you\\'d like me to search for the latest paper on? For example, are you interested in the latest Machine Learning papers, Quantum Physics discoveries, Computational Biology advances, or something else? Let me know and I\\'ll search for the most recent top papers in that area.', 'type': 'text', 'index': 0}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about a latest paper in Arxiv',\n",
       " 'output': [{'text': '<thinking>\\nThe arxiv tool seems most relevant to answer this query since it allows searching for the latest scientific articles on arxiv.org in a variety of fields. To use the arxiv tool, I need to provide a search query.\\n\\nThe user has requested information about a \"latest paper in Arxiv\", but hasn\\'t specified a particular subject area. To get the most relevant latest paper, it would help to narrow down the search to a specific field or topic.\\n\\nSince the user didn\\'t provide a particular area to focus on, I will ask them to clarify what subject they are most interested in hearing about the latest research on. This additional context will allow me to construct a more targeted search query for the arxiv tool.\\n</thinking>\\n\\nTo find the most relevant latest paper on Arxiv for you, it would help to know what subject area or topic you are most interested in. Arxiv covers a wide range of fields including Physics, Mathematics, Computer Science, Biology, Finance, Statistics, Engineering, and Economics.\\n\\nCould you specify a particular subject you\\'d like me to search for the latest paper on? For example, are you interested in the latest Machine Learning papers, Quantum Physics discoveries, Computational Biology advances, or something else? Let me know and I\\'ll search for the most recent top papers in that area.',\n",
       "   'type': 'text',\n",
       "   'index': 0}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about a latest paper in Arxiv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
